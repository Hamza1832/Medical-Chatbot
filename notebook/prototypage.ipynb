{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text length: 79\n",
      "Cleaned text length: 0\n",
      "Cleaned text saved to cleaned_book.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# =========================\n",
    "# 1ï¸âƒ£ Load PDF and extract text\n",
    "# =========================\n",
    "pdf_path = r\"C:\\Users\\hamza\\Desktop\\Medical-Chatbot\\data\\pdfcoffee.com_medical-books-free-pathophysiology-of-disease-an-introduction-to-clinical-medicine-8th-edition-pdf-pdf-free.pdf\"  # Replace with your PDF path\n",
    "reader = PdfReader(pdf_path)\n",
    "raw_text = \"\"\n",
    "\n",
    "for page in reader.pages:\n",
    "    raw_text += page.extract_text() + \"\\n\"\n",
    "\n",
    "print(\"Raw text length:\", len(raw_text))\n",
    "\n",
    "# =========================\n",
    "# 2ï¸âƒ£ Clean text\n",
    "# =========================\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove page numbers like \"Page 12\" or \"12\"\n",
    "    text = re.sub(r'Page \\d+', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\n\\d+\\n', '\\n', text)  # standalone numbers on lines\n",
    "    \n",
    "    # Remove headers/footers if known patterns exist (e.g., book title repeated)\n",
    "    text = re.sub(r'Robbins Basic Pathology.*', '', text)  # example\n",
    "    \n",
    "    # Strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "cleaned_text = clean_text(raw_text)\n",
    "\n",
    "print(\"Cleaned text length:\", len(cleaned_text))\n",
    "\n",
    "# =========================\n",
    "# 3ï¸âƒ£ Save cleaned text to a file\n",
    "# =========================\n",
    "with open(\"cleaned_book.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned_text)\n",
    "\n",
    "print(\"Cleaned text saved to cleaned_book.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56e87ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb56cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m chunks = split_text_custom(cleaned_text, chunk_size=\u001b[32m4000\u001b[39m, overlap=\u001b[32m800\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal chunks created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSample chunk:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[32m500\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Custom text splitter for RAG\n",
    "# =========================\n",
    "def split_text_custom(text, chunk_size=4000, overlap=800):\n",
    "    \"\"\"\n",
    "    Splits text into chunks of chunk_size characters with overlap.\n",
    "    Approx 1000 tokens ~ 4000 characters.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "    \n",
    "    while start < text_length:\n",
    "        end = min(start + chunk_size, text_length)\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap  # move start by chunk_size - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# =========================\n",
    "# Load cleaned text\n",
    "# =========================\n",
    "with open(\"cleaned_book.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cleaned_text = f.read()\n",
    "\n",
    "# =========================\n",
    "# Split text into chunks\n",
    "# =========================\n",
    "chunks = split_text_custom(cleaned_text, chunk_size=4000, overlap=800)\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "print(\"Sample chunk:\\n\", chunks[0][:500], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "863b5aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk 1/1005\n",
      "Processed chunk 51/1005\n",
      "Processed chunk 101/1005\n",
      "Processed chunk 151/1005\n",
      "Processed chunk 201/1005\n",
      "Processed chunk 251/1005\n",
      "Processed chunk 301/1005\n",
      "Processed chunk 351/1005\n",
      "Processed chunk 401/1005\n",
      "Processed chunk 451/1005\n",
      "Processed chunk 501/1005\n",
      "Processed chunk 551/1005\n",
      "Processed chunk 601/1005\n",
      "Processed chunk 651/1005\n",
      "Processed chunk 701/1005\n",
      "Processed chunk 751/1005\n",
      "Processed chunk 801/1005\n",
      "Processed chunk 851/1005\n",
      "Processed chunk 901/1005\n",
      "Processed chunk 951/1005\n",
      "Processed chunk 1001/1005\n",
      "\n",
      "--- Test similarity ---\n",
      "(852, 'pression on local vessel endothelium to facilitate neutrophil adhesion and migration and are also potent chemoattractants for neutrophils. Neutrophils also amplify their own recruitment by releasing leukotriene LTB 4 upon urate crystal phagocytosis (see Figure 24â€“2 ). FIGURE 24â€“2 The mechanisms of the initiation and amplification of the acute inflammatory response in gout involve both cytokines and humoral mediators. The intense inflammatory response in gout typically resolves spontaneously and completely over the course of several days, even without therapy. This down-modulation of the inflammatory response is a typical feature of acute inflammation, whereby the inflammatory response itself successfully removes the pro-inflammatory stimulus ( Table 24â€“1 ). Numerous mechanisms appear to be responsible: (1) efficient crystal phagocytosis, preventing the activation of newly recruited inflammatory cells; (2) increased heat and fluid influx, altering the local physical and chemical conditions to favor crystal solubilization; (3) coating of crystals with serum proteins, rendering the surface of the crystals less inflammatory; (4) secretion of a variety of anti-inflammatory cytokines (eg, TGF-Î²) by activated joint macrophages; and (5) phagocytosis of previously activated apoptotic neutrophils by macrophages in the joint, altering the balance of cytokines secreted by these macrophages in such a way that pro-inflammatory cytokine secretion is inhibited while anti-inflammatory cytokine secretion is enhanced. TABLE 24â€“1 Mechanisms causing down-modulation of the inflammatory response in gout. Thus, gout represents an excellent example of an acute inflammatory response initiated by a pro-inflammatory force. The response is acute, highly focused, and self-limited rather than self-sustaining and is associated with little tissue destruction in the acute phase. Flares of disease represent a recurrence of crystals in a pro-inflammatory form in the joints. Myelomonocytic cells and humoral factors (eg, cytokines and the complement and kinin cascades) are critical mediators of the acute syndrome. Clinical Manifestations A. Podagra and Episodic Oligoarticular Arthritis Podagraâ€”severe inflammatory arthritis at the first metatarsophalangeal jointâ€”is the most frequent manifestation of gout. Patients typically describe waking in the middle of the night with dramatic pain, redness, swelling, and warmth of the area. Flares of gout typically produce one of the most intense forms of inflammatory arthritis. The toes and, to a lesser extent, the midfoot, ankles and knees, are the most common sites for gout flares. Gout attacks frequently occur in circumstances that increase serum uric acid levels, such as metabolic stressors leading to increased DNA or adenosine triphosphate (ATP) turnover (eg, sepsis or surgery) or dehydration. Agents that reduce prostaglandin synthesis (eg, nonsteroidal anti-inflammatory drugs), reduce neutrophil migration into the joints (eg, colchicine), or decrease the activation of myelomonocytic cells (eg, corticosteroids) reduce the duration of a gouty flare. Gouty arthritis can be diagnosed by examining synovial fluid aspirated from an actively inflamed joint under a polarizing microscope. Monosodium urate crystals can be seen as negatively birefringent, needle-like structures that extend across the diameter of and are engulfed by polymorphonuclear neutrophils. B. Tophi Formation Firm, irregular, subcutaneous deposits of monosodium urate crystals may occur in patients with chronic gout and are referred to as tophi. A tophus most often forms along tendinous tissues on the extensor surfaces of joints and tendons, as well as on the outer helix of the ear. Such tophi may extrude chalky material, containing urate crystals, onto the skin surface that can be viewed for diagnostic purposes using polarized microscopy. C. Chronic Erosive Polyarthritis In some patients, the total body burden of uric acid increases greatly over years; deposits', 0.6147404611110687)\n",
      "(848, 'stemic lupus erythematosus [SLE], rheumatoid arthritis) is often remote and no longer recognizable once the unique disease phenotype becomes fully established and the diagnosis clear. Propagation of the disease typically occurs as a result of an autoimmune response that induces a self-amplifying cycle of damage. Autoimmune diseases are characteristically driven by â€œself-antigensâ€ (eg, nucleosomes [composed of DNA and histones] in SLE) and can elicit both cellular and humoral immune responses. Conditions leading to the initiation of chronic autoimmune diseases occur rarely, but once a disease is established, flares are frequent. This circumstance probably reflects the abundant capacity of the immune system to â€œrememberâ€ previously encountered antigens and to respond to them with greater vigor when encountered again, even at lower concentrations (see Figure 24â€“1 ). Different tissues are affected in various diseases (eg, specific synovial joints in gout and rheumatoid arthritis; skin, joints, kidneys, serosal surfaces, nervous system, and blood cell lines in SLE). PATHOGENESIS OF INFLAMMATION The nature of tissue damage and joint injury is determined in part by the inflammatory and immune effector functions that predominate. In addition, the pathologic features of the chronic inflammatory disorders reflect the combination of inflammatory damage and the consequences of healing. ENDOTHELIAL ACTIVATION The recruitment and activation of specific subsets of inflammatory and immune cells are essential determinants of the pathologic features. In this regard, the role of regional blood vessel endothelium activation by pro-inflammatory cytokines (eg, tumor necrosis factor alpha [TNFÎ±], interleukin [IL]-1Î²) must be emphasized. Several cytokines induce the expression on endothelial cells of ligands for the adhesion-promoting receptors of inflammatory cells (integrins and selectins) and allow neutrophils and monocytes to adhere to the vessel wall in the inflamed area and migrate into the underlying tissues. CYTOKINES Distinct classes of immune effector function are activated depending on the pattern of cytokines that predominate during initiation of the inflammatory response. For example, some cytokines (eg, IL-12) produced by infected monocyte-macrophages skew the lymphocyte response toward T H 1 cells (which generate the T H 1 cytokines IL-2, interferon-Î³, and TNFÎ±) that are associated with activating macrophage killing functions and protecting against invading intracellular pathogens. In contrast, the presence of IL-4 during the initial response induces the differentiation of T H 2 lymphocytes, which generate T H 2 cytokines (eg, IL-4, IL-5, IL-6, IL-10). These cytokines have their predominant function in activating B cells and generating antibodies. A new subset of helper T cells that develop in the presence of the cytokines TGF-Î³ and IL-6 has recently been described. These cells are termed T H 17 cells because of their characteristic secretion of IL-17. They appear to be critically involved in recruiting granulocytes, protecting against certain types of bacteria, and generating chronic inflammation and autoimmunity. Although significant overlap exists, specific pathologic features tend to accompany the different cytokine patterns (eg, granulomas for T H 1 versus immune complex disease for T H 2). In addition, significant data point to an important role for type I interferons in inducing novel pathways of monocyte differentiation in patients with SLE that enhance responses to â€œself-antigens.â€ COMPLEMENT PATHWAY The classical complement pathway is activated when antibody binds to its specific antigen. Activation of the complement cascade induces inflammatory cell recruitment and activation (with all the consequences mentioned later), other features of the acute inflammatory response (eg, increased capillary permeability), and cellular damage mediated by terminal components of the complement cascade (ie, membrane attack complex). MYELOMONO', 0.6180493831634521)\n",
      "(95, 'portant consequence of inflammation is that the pH of the inflamed tissues is lowered, creating an inhospitable environment for the microbe. The increased blood flow to the area allows continued recruitment of inflammatory cells as well as the necessary components for tissue repair and recovery. When a microorganism enters host tissue, it activates circulating proteins including complement (see below) and induces the release of pro-inflammatory cytokines. These mediators result in the increased vascular permeability and vasodilation characteristic of inflammation. For example, the anaphylatoxins C3a, C4a, and C5a, produced by the activation of complement, stimulate the release of histamine from mast cells. Histamine dilates the blood vessels and further increases their permeability. Bradykinin is also released, increasing vascular permeability. Pro-inflammatory cytokines include interleukin-1 (IL-1), IL-6, tumor necrosis factor, and interferon-Î³. These factors, singly or in combination, promote fever, produce local inflammatory signs, and trigger catabolic responses. During severe infection, a change in hepatic synthesis of proteins occurs, resulting in an increase in some proteins and a decrease in others. Most notable is the increase in acute-phase reactants , which include rheumatoid factor, C-reactive protein (CRP), ferritin, and various proteinase inhibitors. The erythrocyte sedimentation rate (ESR), a nonspecific marker of inflammation, also increases, although in a slower fashion. A catabolic state is further augmented by simultaneous increases in levels of circulating cortisol, glucagon, catecholamines, and other hormones. Mild to moderate inflammatory responses serve important host defense functions. For example, elevated body temperature may inhibit viral replication. Inflammatory hyperemia and systemic neutrophilia optimize phagocyte delivery to sites of infection. Decreased availability of iron inhibits the growth of microbes such as Yersinia that require this element as a nutrient. However, when the inflammatory responses become extreme, extensive tissue damage can result, as in the case of sepsis. COMPLEMENT SYSTEM The complement system is composed of a series of plasma protein and cell membrane receptors that are important mediators of host defenses and inflammation ( Figure 4â€“4 ). Most of the biologically significant effects of the complement system are mediated by the third component (C3) and the terminal components (C5â€“9). These crucial proteins are activated through one of two mechanisms, termed the classic and alternative pathways. The classic pathway is activated by antigenâ€“antibody complexes or antibody-coated particles, and the alternative pathway is activated by mechanisms independent of antibodies, usually by interaction with bacterial surface components. Both pathways form C3 convertase, which cleaves the C3 component of complement, a key protein common to both pathways. The two pathways then proceed in identical fashion to bind late-acting components to form a membrane attack complex (C5â€“9), which results in target cell lysis. FIGURE 4â€“4 Complement reaction sequence and infections associated with deficiency states. (Redrawn, with permission, from Detrick B. Immunology. In: Carroll KC et al, eds. Jawetz, Melnick, and Adelbergâ€™s Medical Microbiology , 27th ed. McGraw-Hill, 2015.) Once activated, complement functions to enhance the antimicrobial defenses in several ways. Complement facilitates phagocytosis by serving as an opsonin , binding to invading microorganisms and making them susceptible to engulfment and destruction by neutrophils and macrophages. The complement-derived membrane attack complex inserts itself into the membrane of a target organism, leading to increased permeability and subsequent lysis of the cell. Complement also acts indirectly by producing substances that are chemotactic for white blood cells. Inherited disorders of complement are associated with an increased risk of bacterial', 0.623603679156522)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 0ï¸âƒ£ Imports (keep your existing ones)\n",
    "# ------------------------------\n",
    "import psycopg\n",
    "from psycopg import Cursor\n",
    "import ollama\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------\n",
    "# 1ï¸âƒ£ Variables\n",
    "# ------------------------------\n",
    "EMBED_MODEL = \"embeddinggemma\"  # Your Ollama embedding model\n",
    "db_connection_str = \"dbname=medical_rag user=postgres password=1803 host=localhost port=5432\"\n",
    "\n",
    "# If your chunks are already in memory\n",
    "# chunks = [...]  # list of strings from the previous splitting step\n",
    "\n",
    "# ------------------------------\n",
    "# 2ï¸âƒ£ Helper functions (reuse yours)\n",
    "# ------------------------------\n",
    "\n",
    "def calculate_embeddings(corpus: str) -> list[float]:\n",
    "    response = ollama.embeddings(EMBED_MODEL, corpus)\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def to_pgvector(vec: list[float]) -> str:\n",
    "    return \"[\" + \",\".join(str(v) for v in vec) + \"]\"\n",
    "\n",
    "def save_embedding(corpus: str, embedding: list[float], cursor: Cursor) -> None:\n",
    "    pg_vec = to_pgvector(embedding)\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO embeddings (corpus, embedding)\n",
    "        VALUES (%s, %s::vector)\n",
    "        \"\"\",\n",
    "        (corpus, pg_vec),\n",
    "    )\n",
    "\n",
    "def similar_corpus(input_corpus: str, k: int, cursor: Cursor):\n",
    "    embedding = calculate_embeddings(input_corpus)\n",
    "    pg_vec = to_pgvector(embedding)\n",
    "\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT id, corpus, embedding <=> %s::vector AS distance\n",
    "        FROM embeddings\n",
    "        ORDER BY distance ASC\n",
    "        LIMIT %s\n",
    "        \"\"\",\n",
    "        (pg_vec, k),\n",
    "    )\n",
    "\n",
    "    return cursor.fetchall()\n",
    "\n",
    "# ------------------------------\n",
    "# 3ï¸âƒ£ Store chunk embeddings in PostgreSQL\n",
    "# ------------------------------\n",
    "with psycopg.connect(db_connection_str) as conn:\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        # Drop old table if exists\n",
    "        cur.execute(\"DROP TABLE IF EXISTS embeddings\")\n",
    "\n",
    "        # Create extension pgvector\n",
    "        cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n",
    "\n",
    "        # Create embeddings table\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS embeddings (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                corpus TEXT,\n",
    "                embedding VECTOR(768)\n",
    "            );\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        # Iterate through your chunks\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            emb = calculate_embeddings(chunk)\n",
    "            save_embedding(chunk, emb, cur)\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Processed chunk {i+1}/{len(chunks)}\")\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        # Optional: test similarity search\n",
    "        print(\"\\n--- Test similarity ---\")\n",
    "        test_results = similar_corpus(\"What causes inflammation?\", 3, cur)\n",
    "        for r in test_results:\n",
    "            print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                  ğŸ“ EDUCATIONAL MEDICAL AI PROJECT                  â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘  Multi-Agent System Demo:                                          â•‘\n",
      "â•‘    ğŸ§  Brain Scan Analysis (Vision + RAG + AI)                       â•‘\n",
      "â•‘    ğŸ’¬ Medical Q&A (RAG-based)                                       â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘  Commands:                                                         â•‘\n",
      "â•‘    'analyze <image_path>' - Analyze brain scan                     â•‘\n",
      "â•‘    Just type your question - Medical Q&A                           â•‘\n",
      "â•‘    'exit', 'quit', 'q' - Exit program                              â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘  âš ï¸  EDUCATIONAL USE ONLY - Not for medical diagnosis              â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "ğŸ” Starting analysis of: C:\\Users\\hamza\\Desktop\\Medical-Chatbot\\data\\Y10.jpg\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘        ğŸ“ EDUCATIONAL AI PROJECT - Brain Tumor Analysis Demo        â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– AGENT 1: Vision Description\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   ğŸ‘ï¸  Getting image description...\n",
      "   ğŸ“‚ Image: Y10.jpg (0.01 MB)\n",
      "   ğŸ”„ Processing...\n",
      "   ğŸ¤– Analyzing image (30-60 sec)...\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "import ollama\n",
    "from groq import Groq\n",
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# ------------------------------\n",
    "# Variables\n",
    "# ------------------------------\n",
    "EMBED_MODEL = \"embeddinggemma\"\n",
    "LLM_MODEL = \"llama3\"\n",
    "VISION_MODEL = \"llama3.2-vision\"\n",
    "GROQ_MODEL = \"llama-3.3-70b-versatile\"\n",
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "db_connection_str = \"dbname=rag_chatbot user=postgres password=1803 host=localhost port=5432\"\n",
    "TOP_K = 5\n",
    "\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------\n",
    "\n",
    "def calculate_embeddings(corpus: str) -> list[float]:\n",
    "    \"\"\"Get embeddings from Ollama embedding model.\"\"\"\n",
    "    response = ollama.embeddings(EMBED_MODEL, corpus)\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def to_pgvector(vec: list[float]) -> str:\n",
    "    \"\"\"Convert list[float] to Postgres vector string.\"\"\"\n",
    "    return \"[\" + \",\".join(str(v) for v in vec) + \"]\"\n",
    "\n",
    "def retrieve_chunks(query: str, k: int = TOP_K):\n",
    "    \"\"\"Retrieve top-k most similar chunks from pgvector.\"\"\"\n",
    "    embedding = calculate_embeddings(query)\n",
    "    pg_vec = to_pgvector(embedding)\n",
    "\n",
    "    with psycopg.connect(db_connection_str) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                SELECT corpus, embedding <=> %s::vector AS distance\n",
    "                FROM embeddings\n",
    "                ORDER BY distance ASC\n",
    "                LIMIT %s\n",
    "                \"\"\",\n",
    "                (pg_vec, k)\n",
    "            )\n",
    "            results = cur.fetchall()\n",
    "    \n",
    "    return [r[0] for r in results]\n",
    "\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    \"\"\"Convert image file to base64 string.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# ------------------------------\n",
    "# AGENT 1: Vision Agent (Llama 3.2 Vision) - SIMPLIFIED\n",
    "# ------------------------------\n",
    "def vision_agent(image_path: str) -> dict:\n",
    "    \"\"\"Simple image description for educational project.\"\"\"\n",
    "    print(\"   ğŸ‘ï¸  Getting image description...\")\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Image file not found: {image_path}\",\n",
    "                \"description\": None\n",
    "            }\n",
    "        \n",
    "        file_size = os.path.getsize(image_path) / (1024 * 1024)\n",
    "        print(f\"   ğŸ“‚ Image: {os.path.basename(image_path)} ({file_size:.2f} MB)\")\n",
    "        \n",
    "        print(f\"   ğŸ”„ Processing...\")\n",
    "        image_base64 = encode_image_to_base64(image_path)\n",
    "        \n",
    "        print(\"   ğŸ¤– Analyzing image (30-60 sec)...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # SIMPLIFIED PROMPT - Just describe what you see\n",
    "        response = ollama.chat(\n",
    "            model=VISION_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"\"\"This is for an educational AI project. Simply describe what you see in this brain scan image:\n",
    "\n",
    "- What type of medical image is this?\n",
    "- What structures or features are visible?\n",
    "- Describe any notable areas, shapes, or patterns you observe\n",
    "- Note the colors, contrasts, and any distinct regions\n",
    "\n",
    "Just give a simple, factual description of what's visible in the image.\"\"\",\n",
    "                    \"images\": [image_base64]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"   âœ“ Analysis complete ({elapsed:.1f}s)\")\n",
    "        \n",
    "        description = response['message']['content']\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"description\": description,\n",
    "            \"image_path\": image_path\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"description\": None\n",
    "        }\n",
    "\n",
    "# ------------------------------\n",
    "# AGENT 2: Tumor Classification Agent (LLaMA 3 + RAG)\n",
    "# ------------------------------\n",
    "def tumor_classification_agent(vision_description: str) -> dict:\n",
    "    \"\"\"Classify tumor type based on description - EDUCATIONAL PROJECT.\"\"\"\n",
    "    print(\"   ğŸ”¬ Searching medical database...\")\n",
    "    \n",
    "    # Search for relevant medical information\n",
    "    search_query = f\"brain tumor types classification characteristics symptoms {vision_description[:200]}\"\n",
    "    chunks = retrieve_chunks(search_query, TOP_K)\n",
    "    \n",
    "    print(f\"   âœ“ Found {len(chunks)} relevant sources\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(chunks) if chunks else \"Limited textbook information available.\"\n",
    "    \n",
    "    print(\"   ğŸ§  Analyzing with AI...\")\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are helping with an educational AI project about brain tumor classification. Provide informative, educational content.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"This is for an educational AI/ML project demonstrating multi-agent systems.\n",
    "\n",
    "IMAGE DESCRIPTION:\n",
    "{vision_description}\n",
    "\n",
    "MEDICAL REFERENCE MATERIAL:\n",
    "{context}\n",
    "\n",
    "Based on the image description, provide an EDUCATIONAL analysis covering:\n",
    "\n",
    "1. **Possible Tumor Type** (educational guess based on description)\n",
    "   - What this might resemble\n",
    "   - Common characteristics\n",
    "\n",
    "2. **Key Features Observed**\n",
    "   - What the description suggests\n",
    "   - Typical patterns for this type\n",
    "\n",
    "3. **General Information** \n",
    "   - How these tumors typically present\n",
    "   - Common locations and characteristics\n",
    "\n",
    "4. **Educational Context**\n",
    "   - Why certain features are significant\n",
    "   - What medical professionals look for\n",
    "\n",
    "Remember: This is a STUDENT PROJECT for learning about AI systems, not actual medical diagnosis.\n",
    "\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(LLM_MODEL, messages=messages)\n",
    "    classification = response['message']['content']\n",
    "    \n",
    "    print(\"   âœ“ Analysis complete!\")\n",
    "    \n",
    "    return {\n",
    "        \"classification\": classification,\n",
    "        \"textbook_chunks_used\": len(chunks)\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# AGENT 3: Educational Information Agent (Groq)\n",
    "# ------------------------------\n",
    "def recommendation_agent(vision_description: str, classification: str) -> str:\n",
    "    \"\"\"Provide educational medical information using Groq.\"\"\"\n",
    "    print(\"   ğŸ“š Generating educational content...\")\n",
    "    \n",
    "    try:\n",
    "        completion = groq_client.chat.completions.create(\n",
    "            model=GROQ_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an educational medical AI helping students learn about brain tumors and medical AI systems. Provide informative, educational content.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"This is for a STUDENT PROJECT demonstrating multi-agent AI systems. NOT for actual medical use.\n",
    "\n",
    "IMAGE DESCRIPTION:\n",
    "{vision_description}\n",
    "\n",
    "AI CLASSIFICATION:\n",
    "{classification}\n",
    "\n",
    "Provide EDUCATIONAL INFORMATION about this type of condition:\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ğŸ“š EDUCATIONAL OVERVIEW\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "General information about this type of brain tumor for learning purposes.\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ğŸ”¬ TYPICAL CHARACTERISTICS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "What features are typically seen with this condition.\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ğŸ¥ GENERAL TREATMENT APPROACHES\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Common treatment methods used for these conditions (educational overview):\n",
    "- Surgical approaches\n",
    "- Radiation options\n",
    "- Medication therapies\n",
    "- Other interventions\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ğŸ“Š MEDICAL PROCESS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "How doctors typically approach diagnosis and treatment (for learning):\n",
    "- Diagnostic steps\n",
    "- Specialist involvement\n",
    "- Treatment planning\n",
    "- Follow-up care\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ğŸ’¡ LEARNING POINTS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Key takeaways for understanding this condition and how AI can assist in medical education.\n",
    "\n",
    "CLEARLY STATE: This is educational content for a student AI project, not medical advice.\n",
    "\"\"\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=2500\n",
    "        )\n",
    "        \n",
    "        print(\"   âœ“ Educational content generated!\")\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {e}\")\n",
    "        return f\"Unable to generate educational content: {str(e)}\"\n",
    "\n",
    "# ------------------------------\n",
    "# Multi-Agent Brain Tumor Analysis Pipeline\n",
    "# ------------------------------\n",
    "def analyze_brain_tumor(image_path: str) -> dict:\n",
    "    \"\"\"Educational brain tumor analysis demo.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "    print(\"â•‘\" + \" ğŸ“ EDUCATIONAL AI PROJECT - Brain Tumor Analysis Demo \".center(68) + \"â•‘\")\n",
    "    print(\"â•š\" + \"â•\"*68 + \"â•\")\n",
    "    \n",
    "    # AGENT 1: Vision Analysis\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ğŸ¤– AGENT 1: Vision Description\")\n",
    "    print(\"â”€\"*70)\n",
    "    \n",
    "    vision_result = vision_agent(image_path)\n",
    "    \n",
    "    if not vision_result[\"success\"]:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": vision_result['error']\n",
    "        }\n",
    "    \n",
    "    # AGENT 2: Classification\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ğŸ¤– AGENT 2: Medical Knowledge Analysis\")\n",
    "    print(\"â”€\"*70)\n",
    "    \n",
    "    classification_result = tumor_classification_agent(vision_result[\"description\"])\n",
    "    \n",
    "    # AGENT 3: Educational Info\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ğŸ¤– AGENT 3: Educational Information\")\n",
    "    print(\"â”€\"*70)\n",
    "    \n",
    "    recommendations = recommendation_agent(\n",
    "        vision_result[\"description\"],\n",
    "        classification_result[\"classification\"]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"vision_analysis\": vision_result[\"description\"],\n",
    "        \"tumor_classification\": classification_result[\"classification\"],\n",
    "        \"recommendations\": recommendations,\n",
    "        \"textbook_sources\": classification_result[\"textbook_chunks_used\"],\n",
    "        \"image_path\": image_path\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Text-Based Query Functions\n",
    "# ------------------------------\n",
    "def route_query(query: str) -> str:\n",
    "    \"\"\"Route text queries to categories.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a medical query classifier.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Classify into ONE category: textbook, medication, emergency, lifestyle, or general.\n",
    "Query: {query}\n",
    "Respond with ONLY the category name.\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(LLM_MODEL, messages=messages)\n",
    "    category = response['message']['content'].strip().lower()\n",
    "    \n",
    "    valid = [\"textbook\", \"medication\", \"emergency\", \"lifestyle\", \"general\"]\n",
    "    return category if category in valid else \"general\"\n",
    "\n",
    "def textbook_agent(query: str) -> str:\n",
    "    \"\"\"Answer using textbook RAG.\"\"\"\n",
    "    print(\"   ğŸ“š Searching medical textbook...\")\n",
    "    chunks = retrieve_chunks(query, TOP_K)\n",
    "    \n",
    "    if not chunks:\n",
    "        return \"No relevant information found in textbook.\"\n",
    "    \n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a medical textbook expert.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer based on the context:\"}\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(LLM_MODEL, messages=messages)\n",
    "    return response['message']['content']\n",
    "\n",
    "def enrichment_agent(query: str, textbook_answer: str, category: str) -> str:\n",
    "    \"\"\"Enrich answer with Groq.\"\"\"\n",
    "    print(\"   ğŸŒŸ Enriching with additional info...\")\n",
    "    \n",
    "    try:\n",
    "        completion = groq_client.chat.completions.create(\n",
    "            model=GROQ_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical expert educator.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Question: {query}\\n\\nTextbook: {textbook_answer}\\n\\nEnrich with practical advice and context:\"}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return textbook_answer + f\"\\n\\n(Additional enrichment unavailable)\"\n",
    "\n",
    "def ask_multiagent_text(query: str) -> dict:\n",
    "    \"\"\"Handle text queries.\"\"\"\n",
    "    category = route_query(query)\n",
    "    textbook_answer = textbook_agent(query)\n",
    "    enriched_answer = enrichment_agent(query, textbook_answer, category)\n",
    "    \n",
    "    return {\n",
    "        \"category\": category,\n",
    "        \"textbook_answer\": textbook_answer,\n",
    "        \"final_answer\": enriched_answer\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Main Interactive Loop\n",
    "# ------------------------------\n",
    "def main():\n",
    "    print(\"\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "    print(\"â•‘\" + \" ğŸ“ EDUCATIONAL MEDICAL AI PROJECT \".center(68) + \"â•‘\")\n",
    "    print(\"â• \" + \"â•\"*68 + \"â•£\")\n",
    "    print(\"â•‘  Multi-Agent System Demo:\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•‘    ğŸ§  Brain Scan Analysis (Vision + RAG + AI)\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•‘    ğŸ’¬ Medical Q&A (RAG-based)\".ljust(69) + \"â•‘\")\n",
    "    print(\"â• \" + \"â•\"*68 + \"â•£\")\n",
    "    print(\"â•‘  Commands:\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•‘    'analyze <image_path>' - Analyze brain scan\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•‘    Just type your question - Medical Q&A\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•‘    'exit', 'quit', 'q' - Exit program\".ljust(69) + \"â•‘\")\n",
    "    print(\"â• \" + \"â•\"*68 + \"â•£\")\n",
    "    print(\"â•‘  âš ï¸  EDUCATIONAL USE ONLY - Not for medical diagnosis\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•š\" + \"â•\"*68 + \"â•\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"ğŸ’¬ You: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['exit', 'quit', 'q']:\n",
    "            print(\"\\nğŸ‘‹ Thanks for testing this educational AI project!\\n\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        # Check for brain scan analysis\n",
    "        if user_input.lower().startswith(('analyze ', 'image ', 'scan ')):\n",
    "            parts = user_input.split(maxsplit=1)\n",
    "            if len(parts) < 2:\n",
    "                print(\"âŒ Please provide image path: analyze <path_to_image>\\n\")\n",
    "                continue\n",
    "            \n",
    "            image_path = parts[1].strip().strip('\"').strip(\"'\")\n",
    "            \n",
    "            print(f\"\\nğŸ” Starting analysis of: {image_path}\")\n",
    "            \n",
    "            try:\n",
    "                result = analyze_brain_tumor(image_path)\n",
    "                \n",
    "                if not result[\"success\"]:\n",
    "                    print(f\"\\nâŒ Analysis failed: {result['error']}\\n\")\n",
    "                    continue\n",
    "                \n",
    "                # Display results\n",
    "                print(\"\\n\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "                print(\"â•‘\" + \" ğŸ“Š EDUCATIONAL ANALYSIS RESULTS \".center(68) + \"â•‘\")\n",
    "                print(\"â•š\" + \"â•\"*68 + \"â•\\n\")\n",
    "                \n",
    "                print(\"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "                print(\"â•‘ ğŸ‘ï¸  IMAGE DESCRIPTION (Agent 1)\".ljust(69) + \"â•‘\")\n",
    "                print(\"â•š\" + \"â•\"*68 + \"â•\")\n",
    "                print(result[\"vision_analysis\"])\n",
    "                \n",
    "                print(\"\\n\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "                print(\"â•‘ ğŸ”¬ MEDICAL ANALYSIS (Agent 2)\".ljust(69) + \"â•‘\")\n",
    "                print(f\"â•‘ ğŸ“š Used {result['textbook_sources']} reference sources\".ljust(69) + \"â•‘\")\n",
    "                print(\"â•š\" + \"â•\"*68 + \"â•\")\n",
    "                print(result[\"tumor_classification\"])\n",
    "                \n",
    "                print(\"\\n\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "                print(\"â•‘ ğŸ“š EDUCATIONAL INFORMATION (Agent 3)\".ljust(69) + \"â•‘\")\n",
    "                print(\"â•š\" + \"â•\"*68 + \"â•\")\n",
    "                print(result[\"recommendations\"])\n",
    "                \n",
    "                print(\"\\n\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "                print(\"â•‘ ğŸ“ STUDENT PROJECT DISCLAIMER \".center(68) + \"â•‘\")\n",
    "                print(\"â• \" + \"â•\"*68 + \"â•£\")\n",
    "                print(\"â•‘  This is an EDUCATIONAL AI project demonstration\".ljust(69) + \"â•‘\")\n",
    "                print(\"â•‘  NOT for actual medical diagnosis or advice\".ljust(69) + \"â•‘\")\n",
    "                print(\"â•‘  For real medical concerns, consult healthcare professionals\".ljust(69) + \"â•‘\")\n",
    "                print(\"â•š\" + \"â•\"*68 + \"â•\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Error: {e}\\n\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # Text-based query\n",
    "        else:\n",
    "            try:\n",
    "                print(\"\\nğŸ” Processing your question...\")\n",
    "                result = ask_multiagent_text(user_input)\n",
    "                \n",
    "                print(\"\\n\" + \"â•\"*70)\n",
    "                print(f\"ğŸ“‹ Category: {result['category'].upper()}\")\n",
    "                print(\"â•\"*70)\n",
    "                \n",
    "                print(\"\\nğŸ“š Textbook Answer:\")\n",
    "                print(\"-\"*70)\n",
    "                print(result['textbook_answer'])\n",
    "                \n",
    "                print(\"\\nâœ¨ Enriched Answer:\")\n",
    "                print(\"-\"*70)\n",
    "                print(result['final_answer'])\n",
    "                print(\"\\n\" + \"â•\"*70 + \"\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Error: {e}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43a323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                   ğŸ“ MULTI-AGENT MEDICAL AI DEMO                    â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘  'analyze <path>' - Run 3-agent image analysis                     â•‘\n",
      "â•‘  'exit' - Quit                                                     â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "ğŸ” Starting analysis: C:\\Users\\hamza\\Desktop\\Medical-Chatbot\\data\\Y10.jpg\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                   ğŸ§  3-AGENT IMAGE ANALYSIS DEMO                    â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– AGENT 1: Describe What You See\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   ğŸ‘ï¸  Looking at the image...\n",
      "   ğŸ“‚ File: Y10.jpg (0.01 MB)\n",
      "   ğŸ”„ Reading image...\n",
      "   ğŸ¤– Describing what I see (30-60 sec)...\n",
      "   âœ“ Done! (93.1 seconds)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– AGENT 2: Search Medical Textbook\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   ğŸ”¬ Searching medical textbook...\n",
      "   âœ“ Found 5 relevant sections\n",
      "   ğŸ§  Analyzing...\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "import ollama\n",
    "from groq import Groq\n",
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------\n",
    "# Variables\n",
    "# ------------------------------\n",
    "EMBED_MODEL = \"embeddinggemma\"\n",
    "LLM_MODEL = \"llama3\"\n",
    "VISION_MODEL = \"llama3.2-vision\"\n",
    "GROQ_MODEL = \"llama-3.3-70b-versatile\"\n",
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "db_connection_str = \"dbname=rag_chatbot user=postgres password=1803 host=localhost port=5432\"\n",
    "TOP_K = 5\n",
    "\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = \"analysis_results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------\n",
    "\n",
    "def calculate_embeddings(corpus: str) -> list[float]:\n",
    "    \"\"\"Get embeddings from Ollama embedding model.\"\"\"\n",
    "    response = ollama.embeddings(EMBED_MODEL, corpus)\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def to_pgvector(vec: list[float]) -> str:\n",
    "    \"\"\"Convert list[float] to Postgres vector string.\"\"\"\n",
    "    return \"[\" + \",\".join(str(v) for v in vec) + \"]\"\n",
    "\n",
    "def retrieve_chunks(query: str, k: int = TOP_K):\n",
    "    \"\"\"Retrieve top-k most similar chunks from pgvector.\"\"\"\n",
    "    embedding = calculate_embeddings(query)\n",
    "    pg_vec = to_pgvector(embedding)\n",
    "\n",
    "    with psycopg.connect(db_connection_str) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                SELECT corpus, embedding <=> %s::vector AS distance\n",
    "                FROM embeddings\n",
    "                ORDER BY distance ASC\n",
    "                LIMIT %s\n",
    "                \"\"\",\n",
    "                (pg_vec, k)\n",
    "            )\n",
    "            results = cur.fetchall()\n",
    "    \n",
    "    return [r[0] for r in results]\n",
    "\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    \"\"\"Convert image file to base64 string.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def save_results_to_file(result: dict, filename: str):\n",
    "    \"\"\"Save analysis results to a text file.\"\"\"\n",
    "    filepath = os.path.join(RESULTS_DIR, filename)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"BRAIN SCAN ANALYSIS - EDUCATIONAL AI PROJECT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Image: {result['image_path']}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"AGENT 1: WHAT THE AI SEES IN THE IMAGE\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(result['vision_analysis'])\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"AGENT 2: INFORMATION FROM MEDICAL TEXTBOOK\\n\")\n",
    "        f.write(f\"(Retrieved from {result['textbook_sources']} sources)\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(result['tumor_classification'])\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"AGENT 3: ADDITIONAL EDUCATIONAL INFO\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(result['recommendations'])\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"NOTE: This is a student AI project demo - Not medical advice\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "# ------------------------------\n",
    "# AGENT 1: Vision Agent - SUPER SIMPLE\n",
    "# ------------------------------\n",
    "def vision_agent(image_path: str) -> dict:\n",
    "    \"\"\"Just describe what you see in the image - no medical analysis.\"\"\"\n",
    "    print(\"   ğŸ‘ï¸  Looking at the image...\")\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Image not found: {image_path}\",\n",
    "                \"description\": None\n",
    "            }\n",
    "        \n",
    "        file_size = os.path.getsize(image_path) / (1024 * 1024)\n",
    "        print(f\"   ğŸ“‚ File: {os.path.basename(image_path)} ({file_size:.2f} MB)\")\n",
    "        \n",
    "        print(f\"   ğŸ”„ Reading image...\")\n",
    "        image_base64 = encode_image_to_base64(image_path)\n",
    "        \n",
    "        print(\"   ğŸ¤– Describing what I see (30-60 sec)...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # SUPER SIMPLE PROMPT - Just describe what you see!\n",
    "        response = ollama.chat(\n",
    "            model=VISION_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"\"\"Look at this brain scan image and simply describe what you see. Think of it like describing a picture to someone.\n",
    "\n",
    "Tell me:\n",
    "- Is this a black and white or color image?\n",
    "- What shapes do you see? (circles, ovals, irregular shapes)\n",
    "- Where are these shapes located? (center, left side, right side, top, bottom)\n",
    "- Are there any bright spots or dark spots?\n",
    "- Are there any small circles or dots visible inside?\n",
    "- What's the background like?\n",
    "- Any other notable visual features?\n",
    "\n",
    "Just describe the visual elements you can see - like you're describing any regular image, not a medical scan. Simple, straightforward description.\"\"\",\n",
    "                    \"images\": [image_base64]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"   âœ“ Done! ({elapsed:.1f} seconds)\")\n",
    "        \n",
    "        description = response['message']['content']\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"description\": description,\n",
    "            \"image_path\": image_path\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"description\": None\n",
    "        }\n",
    "\n",
    "# ------------------------------\n",
    "# AGENT 2: Knowledge Agent\n",
    "# ------------------------------\n",
    "def tumor_classification_agent(vision_description: str) -> dict:\n",
    "    \"\"\"Search medical knowledge based on what was seen.\"\"\"\n",
    "    print(\"   ğŸ”¬ Searching medical textbook...\")\n",
    "    \n",
    "    search_query = f\"brain tumor appearance characteristics {vision_description[:250]}\"\n",
    "    chunks = retrieve_chunks(search_query, TOP_K)\n",
    "    \n",
    "    print(f\"   âœ“ Found {len(chunks)} relevant sections\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(chunks) if chunks else \"No specific information found.\"\n",
    "    \n",
    "    print(\"   ğŸ§  Analyzing...\")\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You help students learn about medical conditions. Provide educational information.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Student AI project - educational purposes only.\n",
    "\n",
    "VISUAL DESCRIPTION FROM IMAGE:\n",
    "{vision_description}\n",
    "\n",
    "TEXTBOOK INFORMATION:\n",
    "{context}\n",
    "\n",
    "Based on what was observed in the image and the textbook info, provide:\n",
    "\n",
    "1. **What This Might Look Like**\n",
    "   Based on the visual description, what types of conditions have similar appearances?\n",
    "\n",
    "2. **Key Visual Features**\n",
    "   What features in the description are notable?\n",
    "\n",
    "3. **General Educational Info**\n",
    "   What does the textbook say about these types of findings?\n",
    "\n",
    "Keep it educational and informative. This is for learning about AI + medical knowledge, not diagnosis.\n",
    "\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(LLM_MODEL, messages=messages)\n",
    "    classification = response['message']['content']\n",
    "    \n",
    "    print(\"   âœ“ Complete!\")\n",
    "    \n",
    "    return {\n",
    "        \"classification\": classification,\n",
    "        \"textbook_chunks_used\": len(chunks)\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# AGENT 3: Info Agent\n",
    "# ------------------------------\n",
    "def recommendation_agent(vision_description: str, classification: str) -> str:\n",
    "    \"\"\"Provide additional educational context.\"\"\"\n",
    "    print(\"   ğŸ“š Getting more info...\")\n",
    "    \n",
    "    try:\n",
    "        completion = groq_client.chat.completions.create(\n",
    "            model=GROQ_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You help students learn about medical AI systems. Provide educational content.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"This is a STUDENT PROJECT demonstrating AI systems. Educational only.\n",
    "\n",
    "WHAT WAS SEEN:\n",
    "{vision_description}\n",
    "\n",
    "TEXTBOOK INFO:\n",
    "{classification}\n",
    "\n",
    "Provide brief educational information about:\n",
    "\n",
    "1. **What This Demonstrates**\n",
    "   How this shows AI can process medical images\n",
    "\n",
    "2. **General Medical Context**\n",
    "   Basic info about these types of scans and findings\n",
    "\n",
    "3. **How Doctors Actually Work**\n",
    "   What real doctors do with these scans (for education)\n",
    "\n",
    "4. **Learning Takeaway**\n",
    "   What students can learn from this demo\n",
    "\n",
    "Keep it short and educational. Remind that this is a demo project, not real medical analysis.\n",
    "\"\"\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        \n",
    "        print(\"   âœ“ Done!\")\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {e}\")\n",
    "        return f\"Could not generate additional info: {str(e)}\"\n",
    "\n",
    "# ------------------------------\n",
    "# Analysis Pipeline\n",
    "# ------------------------------\n",
    "def analyze_brain_tumor(image_path: str) -> dict:\n",
    "    \"\"\"Run the 3-agent analysis pipeline.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "    print(\"â•‘\" + \" ğŸ§  3-AGENT IMAGE ANALYSIS DEMO \".center(68) + \"â•‘\")\n",
    "    print(\"â•š\" + \"â•\"*68 + \"â•\")\n",
    "    \n",
    "    # AGENT 1: Vision\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ğŸ¤– AGENT 1: Describe What You See\")\n",
    "    print(\"â”€\"*70)\n",
    "    \n",
    "    vision_result = vision_agent(image_path)\n",
    "    \n",
    "    if not vision_result[\"success\"]:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": vision_result['error']\n",
    "        }\n",
    "    \n",
    "    # AGENT 2: Knowledge Search\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ğŸ¤– AGENT 2: Search Medical Textbook\")\n",
    "    print(\"â”€\"*70)\n",
    "    \n",
    "    classification_result = tumor_classification_agent(vision_result[\"description\"])\n",
    "    \n",
    "    # AGENT 3: Additional Info\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ğŸ¤– AGENT 3: Additional Context\")\n",
    "    print(\"â”€\"*70)\n",
    "    \n",
    "    recommendations = recommendation_agent(\n",
    "        vision_result[\"description\"],\n",
    "        classification_result[\"classification\"]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"vision_analysis\": vision_result[\"description\"],\n",
    "        \"tumor_classification\": classification_result[\"classification\"],\n",
    "        \"recommendations\": recommendations,\n",
    "        \"textbook_sources\": classification_result[\"textbook_chunks_used\"],\n",
    "        \"image_path\": image_path\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Text Query Functions\n",
    "# ------------------------------\n",
    "def route_query(query: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Classify medical queries.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Category (textbook/medication/emergency/lifestyle/general): {query}\"}\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(LLM_MODEL, messages=messages)\n",
    "    category = response['message']['content'].strip().lower()\n",
    "    \n",
    "    valid = [\"textbook\", \"medication\", \"emergency\", \"lifestyle\", \"general\"]\n",
    "    return category if category in valid else \"general\"\n",
    "\n",
    "def textbook_agent(query: str) -> str:\n",
    "    print(\"   ğŸ“š Searching...\")\n",
    "    chunks = retrieve_chunks(query, TOP_K)\n",
    "    \n",
    "    if not chunks:\n",
    "        return \"No info found.\"\n",
    "    \n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Medical educator.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQ: {query}\\nA:\"}\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(LLM_MODEL, messages=messages)\n",
    "    return response['message']['content']\n",
    "\n",
    "def enrichment_agent(query: str, textbook_answer: str) -> str:\n",
    "    print(\"   ğŸŒŸ Enriching...\")\n",
    "    \n",
    "    try:\n",
    "        completion = groq_client.chat.completions.create(\n",
    "            model=GROQ_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Medical expert.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Q: {query}\\nTextbook: {textbook_answer}\\nAdd practical info:\"}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except:\n",
    "        return textbook_answer\n",
    "\n",
    "def ask_multiagent_text(query: str) -> dict:\n",
    "    category = route_query(query)\n",
    "    textbook_answer = textbook_agent(query)\n",
    "    enriched_answer = enrichment_agent(query, textbook_answer)\n",
    "    \n",
    "    return {\n",
    "        \"category\": category,\n",
    "        \"textbook_answer\": textbook_answer,\n",
    "        \"final_answer\": enriched_answer\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Main\n",
    "# ------------------------------\n",
    "def main():\n",
    "    print(\"\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "    print(\"â•‘\" + \" ğŸ“ MULTI-AGENT MEDICAL AI DEMO \".center(68) + \"â•‘\")\n",
    "    print(\"â• \" + \"â•\"*68 + \"â•£\")\n",
    "    print(\"â•‘  'analyze <path>' - Run 3-agent image analysis\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•‘  'exit' - Quit\".ljust(69) + \"â•‘\")\n",
    "    print(\"â•š\" + \"â•\"*68 + \"â•\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"ğŸ’¬ You: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['exit', 'quit', 'q']:\n",
    "            print(\"\\nğŸ‘‹ Thanks for testing!\\n\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        # Image analysis\n",
    "        if user_input.lower().startswith(('analyze ', 'image ', 'scan ')):\n",
    "            parts = user_input.split(maxsplit=1)\n",
    "            if len(parts) < 2:\n",
    "                print(\"âŒ Usage: analyze <path>\\n\")\n",
    "                continue\n",
    "            \n",
    "            image_path = parts[1].strip().strip('\"').strip(\"'\")\n",
    "            \n",
    "            print(f\"\\nğŸ” Starting analysis: {image_path}\")\n",
    "            \n",
    "            try:\n",
    "                result = analyze_brain_tumor(image_path)\n",
    "                \n",
    "                if not result[\"success\"]:\n",
    "                    print(f\"\\nâŒ Failed: {result['error']}\\n\")\n",
    "                    continue\n",
    "                \n",
    "                # Save to file\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"analysis_{timestamp}.txt\"\n",
    "                filepath = save_results_to_file(result, filename)\n",
    "                \n",
    "                # Print results\n",
    "                print(\"\\n\\n\" + \"â•”\" + \"â•\"*68 + \"â•—\")\n",
    "                print(\"â•‘\" + \" âœ… ANALYSIS COMPLETE \".center(68) + \"â•‘\")\n",
    "                print(\"â•š\" + \"â•\"*68 + \"â•\\n\")\n",
    "                \n",
    "                print(\"ğŸ‘ï¸  WHAT THE AI SEES:\")\n",
    "                print(\"-\"*70)\n",
    "                print(result[\"vision_analysis\"])\n",
    "                print()\n",
    "                \n",
    "                print(\"ğŸ“š TEXTBOOK INFO:\")\n",
    "                print(\"-\"*70)\n",
    "                print(result[\"tumor_classification\"])\n",
    "                print()\n",
    "                \n",
    "                print(\"ğŸ’¡ ADDITIONAL CONTEXT:\")\n",
    "                print(\"-\"*70)\n",
    "                print(result[\"recommendations\"])\n",
    "                print()\n",
    "                \n",
    "                print(\"=\"*70)\n",
    "                print(f\"ğŸ“„ Full results saved: {filepath}\")\n",
    "                print(\"=\"*70 + \"\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Error: {e}\\n\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # Text query\n",
    "        else:\n",
    "            try:\n",
    "                result = ask_multiagent_text(user_input)\n",
    "                \n",
    "                print(f\"\\nğŸ“‹ {result['category'].upper()}\")\n",
    "                print(\"=\"*70)\n",
    "                print(\"\\nğŸ“š Textbook:\")\n",
    "                print(result['textbook_answer'])\n",
    "                print(\"\\nâœ¨ Enhanced:\")\n",
    "                print(result['final_answer'])\n",
    "                print(\"=\"*70 + \"\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Error: {e}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
